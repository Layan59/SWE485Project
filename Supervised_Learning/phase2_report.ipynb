{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the preprocessed dataset from a CSV file\n",
    "df_cleaned = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "\n",
    "# Define features (X) by excluding the target variable 'Disease'\n",
    "X = df_cleaned.drop(columns=[\"Disease\"])\n",
    "\n",
    "# Define the target variable (y) as the 'Disease' column\n",
    "y = df_cleaned[\"Disease\"]\n",
    "#X: Contains all columns except Disease (independent features).\n",
    "# y: Contains only the Disease column, which is the target variable (dependent variable).\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# - 80% of the data will be used for training\n",
    "# - 20% will be reserved for testing\n",
    "# - The split maintains the class balance in both sets\n",
    "\n",
    " #Parameters used:\n",
    "# test_size=0.2 → 20% of the data is allocated for testing, 80% for training.\n",
    "# random_state=42 → Ensures reproducibility (consistent split every time the code runs).\n",
    "# stratify=y → Ensures that the proportion of classes remains balanced in both training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Save the training and testing sets to CSV files for future use\n",
    "X_train.to_csv(\"X_train.csv\", index=False)  # Save features of the training set\n",
    "X_test.to_csv(\"X_test.csv\", index=False)    # Save features of the testing set\n",
    "y_train.to_csv(\"y_train.csv\", index=False)  # Save target variable of the training set\n",
    "y_test.to_csv(\"y_test.csv\", index=False)    # Save target variable of the testing set\n",
    "\n",
    "# Display a success message upon completion of the data splitting\n",
    "print(\"Data splitting completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Supervised Learing (SVM AND RANDOM FOREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # For better visualizations\n",
    "import numpy as np\n",
    "import time  \n",
    "\n",
    "# Load train and test datasets\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()  # Convert to 1D array\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "start_time = time.time()  \n",
    "rf_model.fit(X_train, y_train)  \n",
    "training_time = time.time() - start_time  \n",
    "\n",
    "print(f\"Random Forest Training Time: {training_time:.4f} seconds\")  \n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', fmt='d', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Code Explanation\n",
    "\n",
    "This code trains a Support Vector Machine (SVM) model using the training dataset, then evaluates its performance on the test dataset after tuning some hyperparameters to reduce overfitting.\n",
    "\n",
    "## 1️ Loading and Preprocessing the Data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "\n",
    " Convert target labels into the correct shape\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "\n",
    "## 2️ Creating and Training the SVM Model\n",
    "\n",
    "We use the rbf kernel to allow the model to handle complex patterns in the data.\n",
    "\n",
    "      •     C=0.01: Reduces strictness, allowing some errors to improve generalization.\n",
    "\n",
    "      •     gamma=10: Increases the influence of each data point on the decision boundary.\n",
    "\n",
    "      •     max_iter=500: Limits the number of training iterations to prevent overfitting.\n",
    "\n",
    "## 3️ Making Predictions and Evaluating the Model\n",
    "\n",
    "After training, the model makes predictions on X_test, then we calculate accuracy (accuracy_score) and print the classification report (classification_report).\n",
    "\n",
    "\n",
    "## 4️ Confusion Matrix\n",
    "\n",
    "The Confusion Matrix is used to visualize the model’s predictions and errors, displayed using seaborn.heatmap.\n",
    "\n",
    "## Final Outcome After Modifications\n",
    "\n",
    "After tuning C and gamma, the model became better at generalization instead of memorization. The confusion matrix shows some misclassifications, meaning the model is no longer 100% perfect, which is expected and helps prevent overfitting.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # For better visualizations\n",
    "import numpy as np\n",
    "import time  \n",
    "\n",
    "# Load train and test datasets\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()  # Convert to 1D array\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "start_time = time.time()  \n",
    "rf_model.fit(X_train, y_train)  \n",
    "training_time = time.time() - start_time  \n",
    "\n",
    "print(f\"Random Forest Training Time: {training_time:.4f} seconds\")  \n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', fmt='d', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Code Explanation \n",
    "\n",
    "## 1. Import Libraries\n",
    "- Load the necessary libraries for data handling, machine learning, and visualization.\n",
    "\n",
    "## 2. Load Data\n",
    "- Read the training and testing data from CSV files, including both features and labels.\n",
    "\n",
    "## 3. Train the Model\n",
    "- Create a Random Forest model and train it on the training data. Measure how long this takes.\n",
    "\n",
    "## 4. Make Predictions\n",
    "- Use the trained model to predict the labels for the test data.\n",
    "\n",
    "## 5. Evaluate Performance\n",
    "- Calculate the accuracy of the predictions and generate a report that includes important metrics like precision and recall.\n",
    "\n",
    "## 6. Visualize Results\n",
    "- Create and display a confusion matrix to show how well the model performed, indicating correct and incorrect predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Supervised Learning Models: Random Forest vs. Support Vector Machine (SVM)\n",
    "\n",
    "## 1. Justification for Algorithm Selection\n",
    "In this project, we evaluated two popular supervised machine learning models: **Random Forest (RF)** and **Support Vector Machine (SVM)**. We chose these models because they are effective for classification tasks and can handle complex data patterns well.\n",
    "\n",
    "- **Random Forest (RF)**: This is an ensemble learning method that combines multiple decision trees to enhance accuracy and reduce the risk of overfitting. It’s robust and performs well across various datasets.\n",
    "  \n",
    "- **Support Vector Machine (SVM)**: This model identifies the optimal hyperplane to separate different classes, making it effective, especially in high-dimensional spaces.\n",
    "\n",
    "Since there's no one-size-fits-all algorithm, we decided to compare these models empirically using performance metrics like accuracy, training time, and detailed classification reports.\n",
    "\n",
    "## 2. Performance Comparison\n",
    "We tested both models on the same dataset and evaluated their performance based on several criteria. Here’s a summary of our findings:\n",
    "\n",
    "| Metric             | Random Forest (RF) | Support Vector Machine (SVM) |\n",
    "|--------------------|---------------------|-------------------------------|\n",
    "| Accuracy           | 100% (1.0000)       | 80.89% (0.8089)               |\n",
    "| Training Time      | 0.4313 sec          | 1.9852 sec                    |\n",
    "| Precision (avg)    | 1.00                | 0.98                          |\n",
    "| Recall (avg)       | 1.00                | 0.81                          |\n",
    "\n",
    "![Random Forest Result Report](Random%20forest%20result%20report.jpg)\n",
    "\n",
    "![Random Forest Confusion Matrix](Random%20forest%20confusion%20matrix.jpg)\n",
    "\n",
    "\n",
    "![SVM Result Report](Svm%20result%20report.jpg)\n",
    "\n",
    "![Modifying SVM Confusion Matrix](Modifing%20SVM%20confusion%20matrix.jpg)\n",
    "## 3. Interpretation of Results\n",
    "\n",
    "### Random Forest Observations\n",
    "- **Perfect Accuracy**: RF achieved 100% accuracy, meaning it classified all test instances correctly.\n",
    "- **Short Training Time**: The training time was only 0.4313 seconds, making it very efficient.\n",
    "- **No Misclassifications**: The confusion matrix showed no errors, indicating that the model generalized well.\n",
    "- **High Recall and Precision**: These metrics suggest excellent performance across all classes.\n",
    "\n",
    "### SVM Observations\n",
    "- **Accuracy Issues**: SVM had an accuracy of 80.89%, indicating some misclassifications.\n",
    "- **Longer Training Time**: It took 1.9852 seconds to train, which is less efficient than RF.\n",
    "- **Confusion Across Classes**: The confusion matrix indicated errors with various classes, showing that SVM struggled with certain classifications.\n",
    "- **Lower Recall and Precision**: These results suggest SVM had difficulty distinguishing between specific symptoms and diseases.\n",
    "\n",
    "## 4. Final Decision and Conclusion\n",
    "Based on our analysis, Random Forest outperformed SVM across all metrics, including accuracy, training time, and overall classification performance. Its quick training time and perfect accuracy make it the best choice for our disease prediction model.\n",
    "\n",
    "### Key Findings:\n",
    "1. **Perfect Classification**: Random Forest achieved 100% accuracy, while SVM performed lower at 80.89%.\n",
    "2. **Efficiency**: Random Forest trained significantly faster (0.4313 sec) compared to SVM (1.9852 sec).\n",
    "3. **Reliability**: SVM misclassified several instances, as seen in the confusion matrix, which affected its reliability.\n",
    "4. **Better Generalization**: Random Forest showed superior generalization on our dataset, making it the preferred model for disease classification.\n",
    "\n",
    "### Final Choice: ✅ Random Forest Model\n",
    "Given these findings, we confidently selected Random Forest as the best-performing model for our application due to its superior accuracy, efficiency, and reliability in predicting diseases based on symptoms."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
