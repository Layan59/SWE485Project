{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff796e-24a5-43fb-817e-d59f088c978c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "119ea7f0",
   "metadata": {},
   "source": [
    "The goal of the dataset\n",
    "\n",
    "The primary objective of creating this dataset is to facilitate AI-driven disease prediction and personalized health recommendations based on symptom pattern analysis. This dataset offers a systematic correlation between symptoms and diseases, along with descriptive details, prevention, and recommended treatments.

     This dataset was collected to support requirements classification, where symptoms are classified into specific diseases for AI-enabled healthcare decision-making and disease prediction, in which machine learning algorithms are trained to associate symptoms with potential illnesses accurately. The dataset also supports automated health counseling, where AI gives individualized treatment recommendations and preventive measures based on predicted disease.

 
     The dataset will be utilized to train a supervised machine learning model that will accept symptoms entered by users and predict the most probable disease. It will also be incorporated into a generative AI system that gives users lengthy, human-like explanations regarding their condition, suggested treatments, and preventive measures.

    Model Workflow:
    User inputs symptoms (e.g., headache, fever, fatigue).
    The machine learning model predicts the most probable disease (e.g., Influenza).
    The system retrieves the corresponding disease details from the dataset, including:
   • A simplified yet informative description of the disease.
   • Evidence-based treatment recommendations.
   • Personalized preventive advice to minimize risks.

   To ensure accurate prediction, Defect Prediction techniques will be employed to detect cases where the model may provide inaccurate disease predictions due to similar symptoms, poor data, or low-confidence classifications. If a problem is detected, the system will apply remedial actions, which can involve requesting further symptoms or adjusting the prediction algorithm.

   This integration ensures that users receive not only a disease prediction but also AI-generated, easy-to-understand medical insights, making healthcare more accessible, proactive, and data-driven."
    "\n",
    "The source of the dataset\n",
    "\n",
    "The dataset was obtained from Kaggle and consists of diseases with their symptoms, descriptions, precautionary measures, and treatment suggestions.\n",
    " • Dataset URL: [Disease Symptom Description Dataset on Kaggle](https://www.kaggle.com/datasets/itachi9604/disease-symptom-description-dataset)\n",
    "\n",
    "General information:\n",
    "\n",
    "The purpose of this dataset is to help researchers and students create systems connected to healthcare. It contains thorough details on a range of illnesses, including descriptions of the conditions, symptoms, and preventative actions. The dataset can be easily cleaned and processed using data handling techniques in any programming language because it is provided in CSV format.\n",
    "\n",
    "Attributes (Columns):\n",
    "1.\tDisease:\n",
    "o\tType: Categorical (text)\n",
    "o\tDescription: The name of the disease.\n",
    "2.\tSymptoms:\n",
    "o\tType: Text (list of symptoms)\n",
    "o\tDescription: Symptoms commonly associated with the disease.\n",
    "3.\tDescription:\n",
    "o\tType: Text\n",
    "o\tDescription: A brief medical summary of the disease.\n",
    "4.\tPrecautionary Steps:\n",
    "o\tType: Text (multiple columns: Precaution_1, Precaution_2, Precaution_3, Precaution_4)\n",
    "o\tDescription: Suggested measures to prevent the condition from worsening.\n",
    "\n",
    "Note: No particular therapy recommendations are included in the dataset. Nonetheless, the preventative measures offer broad recommendations for handling medical issues.\n",
    "\n",
    "Summary of the dataset\n",
    "\t•\tSample Data Preview:\n",
    "\n",
    "Disease\tSymptom_1\tSymptom_2\tSymptom_3\tSymptom_4\n",
    "Fungal infection\titching\tskin_rash\tnodal_skin_eruptions\tdischromic _patches\n",
    "Fungal infection\tskin_rash\tnodal_skin_eruptions\tdischromic _patches\t\n",
    "Fungal infection\titching\tnodal_skin_eruptions\tdischromic _patches\t\n",
    "Fungal infection\titching\tskin_rash\tdischromic _patches\t\n",
    "Fungal infection\titching\tskin_rash\tnodal_skin_eruptions\t\n",
    "Fungal infection\tskin_rash\tnodal_skin_eruptions\tdischromic _patches\t\n",
    "Fungal infection\titching\tnodal_skin_eruptions\tdischromic _patches\t\n",
    "Fungal infection\titching\tskin_rash\tdischromic _patches\t\n",
    "Fungal infection\titching\tskin_rash\tnodal_skin_eruptions\t\n",
    "Fungal infection\titching\tskin_rash\tnodal_skin_eruptions\tdischromic _patches\n",
    "Allergy\tcontinuous_sneezing\tshivering\tchills\twatering_from_eyes\n",
    "\n",
    "Preprocessing techniques:\n",
    "\n",
    "We used One-Hot Encoding to convert symptoms into numerical values because machine learning models can't handle text and need numerical values to process the data.In this method, each symptom becomes its own column. If the symptom is present, we put 1, and if it's not, we put 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We used pd.read_csv() because it's the standard method for reading CSV files, which is the format the dataset is stored in.This step loads the data into a DataFrame so we can work with it in Python.\n",
    "df = pd.read_csv(\"Dataset/datasetDiseaseSymptomPrediction.csv\")  \n",
    "\n",
    "# The first column (Disease) is the target variable (the disease name), so I want to exclude it when processing symptoms. The rest of the columns represent symptoms, so I need to identify them to perform One-Hot Encoding.\n",
    "symptom_columns = df.columns[1:]  \n",
    "\n",
    "# To make the data easier to process, I combined all symptoms for each patient into a single list. This helps later when applying One-Hot Encoding to the symptoms\n",
    "df[\"Symptoms\"] = df[symptom_columns].values.tolist()\n",
    "\n",
    "# The \"None\" values represent the absence of a symptom, and they don't contribute to the One-Hot Encoding process. So, I removed them to avoid unnecessary noise n the data\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].apply(lambda x: list(set(x) - {\"None\"}))\n",
    "\n",
    "# We used MultiLabelBinarizer to convert the list of symptoms for each patient into numerical values using One-Hot Encoding.\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# MultiLabelBinarizer is an effective tool for converting multi-label data (such as symptoms in this case) into a One-Hot representation. This step is crucial because we need to transform the symptoms into binary values (0 or 1), where 1 means the symptom is present and 0 means it's not.\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# To ensure MultiLabelBinarizer works properly, we convert each symptom to a string. This ensures that the binarizer operates correctly.\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].apply(lambda x: [str(s) for s in x])\n",
    "\n",
    "# This is the core step where One-Hot Encoding is applied.\n",
    "symptom_encoded = mlb.fit_transform(df[\"Symptoms\"])\n",
    "\n",
    "# After applying One-Hot Encoding, the result is a matrix of 0s and 1s. We convert this matrix into a DataFrame with meaningful column names, which are the actual symptoms, This makes it easier to interpret the data and perform further analysis.\n",
    "df_encoded = pd.DataFrame(symptom_encoded, columns=mlb.classes_)\n",
    "\n",
    "# After encoding the symptoms, we need to combine them with the target variable (Disease) to create a comprehensive dataset. This step ensures that the final dataset includes both the disease label and the encoded symptoms\n",
    "df_cleaned = pd.concat([df[[\"Disease\"]], df_encoded], axis=1)\n",
    "\n",
    "# Display all columns in the DataFrame\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.width', None) # Remove any line breaks for large tables\n",
    "\n",
    "# Display the final processed dataset\n",
    "print(df_cleaned.head())  \n",
    "\n",
    "# Once the data is preprocessed, we save it in a new CSV file for future use.\n",
    "df_cleaned.to_csv(\"cleaned_dataset.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730dbcb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c24fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
